{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from groq import Groq\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caminho_arquivos(diretorio):\n",
    "    paths = []\n",
    "    for nome_arquivo in os.listdir(diretorio):\n",
    "        paths.append(os.path.join(diretorio, nome_arquivo))\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_arquivos(diretorio):\n",
    "    textos = []\n",
    "    for nome_arquivo in os.listdir(diretorio):\n",
    "        if nome_arquivo.endswith('.txt'):\n",
    "            with open(os.path.join(diretorio, nome_arquivo), 'r', encoding='utf-8') as file:\n",
    "                textos.append(file.read())\n",
    "    return textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=\"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\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-Processamento dos Textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_arquivo(path):\n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as arquivo:\n",
    "            conteudo = arquivo.read()\n",
    "    except UnicodeDecodeError:\n",
    "        with open(path, 'r', encoding='latin-1') as arquivo:\n",
    "            conteudo = arquivo.read()\n",
    "    return conteudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_texto(texto, tamanho_maximo=10000):\n",
    "    partes = []\n",
    "    while len(texto) > tamanho_maximo:\n",
    "        limite = texto.rfind('.', 0, tamanho_maximo)\n",
    "        if limite == -1:\n",
    "            limite = tamanho_maximo\n",
    "        partes.append(texto[:limite + 1])\n",
    "        texto = texto[limite + 1:].strip()\n",
    "    partes.append(texto)\n",
    "    return partes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processamento(path):\n",
    "    conteudo = ler_arquivo(path)\n",
    "    \n",
    "    partes = dividir_texto(conteudo)\n",
    "    \n",
    "    resultado_final = \"\"\n",
    "    \n",
    "    for parte in partes:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"Você é um assistente que ajuda a pré-processar dados legislativos. \"\n",
    "                        \"Por favor, extraia e organize as informações legislativas do seguinte texto. \"\n",
    "                        \"Certifique-se de remover conteúdo irrelevante, normalizar o texto e estruturá-lo \"\n",
    "                        \"em seções claras. Inclua apenas informações importantes e relevantes sobre as leis, \"\n",
    "                        \"resoluções e normas mencionadas no seguinte texto (tudo o que é informação relevante deve ser escrito, não resuma informações de forma alguma, e corrija erros de escrita se necessário):\\n\\n\"\n",
    "                        f\"{parte}\"\n",
    "                    )\n",
    "                }\n",
    "            ],\n",
    "            model=\"llama3-8b-8192\",\n",
    "        )\n",
    "        \n",
    "        resultado_final += chat_completion.choices[0].message.content + \"\\n\"\n",
    "    \n",
    "    with open(f'pre_processados\\\\{path}', 'w', encoding='utf-8') as file:\n",
    "        file.write(resultado_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "caminhos = caminho_arquivos(\"textos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textos\\decreto_1044_69_afecções_orgânicas.txt\n",
      "textos\\decreto_2494_1998_educação_a_distância.txt\n",
      "textos\\decreto_2561_1998.txt\n",
      "textos\\decreto_5.626_05_língua_brasileira_de_sinais.txt\n",
      "textos\\estatuto_da_ufam.txt\n",
      "textos\\estágio_de_graduação.txt\n",
      "textos\\lei_10.098_2000_libras.txt\n",
      "textos\\lei_9.394_1996_diret_bases_educ_nacional.txt\n",
      "textos\\lei_carteira_estudantil.txt\n",
      "textos\\lei_nº_10.436_2002.txt\n",
      "textos\\lei_nº_12.089_2009.txt\n",
      "textos\\oficio_mec_nomclat_cursos.txt\n",
      "textos\\portaria_1.632_2006_pet.txt\n",
      "textos\\portaria_3.385_2005_mec.txt\n",
      "textos\\portaria_301_1998.txt\n",
      "textos\\portaria_no_1.095_de_25_de_outubro_de_2018_imprensa_nacional.txt\n",
      "textos\\port_048_2019_heteroidentificação.txt\n",
      "textos\\port_04_2002_prazo_ret_documentos.txt\n",
      "textos\\port_05_2020_aproveit_disci_do_pibid.txt\n",
      "textos\\port_2304_95_nada_consta.txt\n",
      "textos\\port_53_plano_de_ação_cursos_2018.txt\n",
      "textos\\port_proeg_propesp_001_2004_programa_mobilidade_.txt\n",
      "textos\\regimento_ufam.txt\n",
      "textos\\resolução_009_1999_consuni.txt\n",
      "textos\\resolução_010_2004_consuni.txt\n",
      "textos\\resolução_010_2007_consad.txt\n",
      "textos\\resolução_013_2009_consepe.txt\n",
      "textos\\resolução_019_2012_matricula_em_disciplina.txt\n",
      "textos\\resolução_021_2007_consepe_aproveit_estudos.txt\n",
      "textos\\resolução_022_livrosbiblioteca.txt\n",
      "textos\\resolução_026_2007_consepe_ceg-1.txt\n",
      "textos\\resolução_027_2010_enade.txt\n",
      "textos\\resolução_044_2015_bonificação.txt\n",
      "textos\\resolução_047_2014_extramacro.txt\n",
      "textos\\resolução_081_2007_consuni.txt\n",
      "textos\\resolução_cne_diretcurricnacionais_out2019.txt\n",
      "textos\\res_011_2007_tranc_matrícula.txt\n",
      "textos\\res_018_2012_oferta_disc_por_semestre.txt\n",
      "textos\\res_030_2015_exclusão_de_alunos_jubilamento.txt\n",
      "textos\\res_037_2011_tempo_máximo_graduação.txt\n",
      "textos\\res_048_2009_consepe_segunda_chamada.txt\n",
      "textos\\res_06_2013_estab_programa_monitoria.txt\n",
      "textos\\res_06_2016_trote.txt\n",
      "textos\\res_070_2011_afinidade_cursos.txt\n",
      "textos\\res_08_2015_nome_social.txt\n",
      "textos\\res_10_2016_disciplinas_presenciais.txt\n",
      "textos\\res_15_2018_trab_voluntario.txt\n",
      "textos\\res_18_2007_ativ_complemtares.txt\n",
      "textos\\res_18_93_créd_optativos.txt\n",
      "textos\\res_20_2019_criação_ext_modificação_curricular.txt\n",
      "textos\\res_23_2017_regime_didático.txt\n",
      "textos\\res_26_2007_inclusão_inf_alunos_disc_turmas.txt\n",
      "textos\\res_2_2015_cne_diretcurric_nacionais.txt\n",
      "textos\\res_31_2015_entrega_revisão_exerc_e_provas.txt\n",
      "textos\\res_32_2016_boletim_diário_classe.txt\n",
      "textos\\res_38_2015_aceleração_de_estudos.txt\n",
      "textos\\res_62_2011_nuc_docentes_estruturantes.txt\n",
      "textos\\res_64_2011_priimes.txt\n",
      "textos\\res_69_2010_curso_de_férias.txt\n",
      "textos\\sei_ufam_1225020_resolução.txt\n"
     ]
    }
   ],
   "source": [
    "for path in caminhos:\n",
    "    pre_processamento(path)\n",
    "    print(path)\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cálculo de quantas perguntas serão geradas por cada texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "diretorio_arquivos = 'pre_processados\\\\textos'\n",
    "textos_legislacao = ler_arquivos(diretorio_arquivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_de_dados = []\n",
    "total_perguntas = 1000\n",
    "texto_tamanho = [len(texto) for texto in textos_legislacao]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_tamanhos = sum(texto_tamanho)\n",
    "proporcao_perguntas = [int((tamanho / soma_tamanhos) * total_perguntas) for tamanho in texto_tamanho]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração das Instruções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_pergunta_resposta(texto_legislacao):\n",
    "    prompt = (\n",
    "        \"Baseado na seguinte legislação:\\n\\n\"\n",
    "        f\"{texto_legislacao}\\n\\n\"\n",
    "        \"Gere uma pergunta e uma resposta que sejam coerentes e relevantes. \"\n",
    "        \"Certifique-se de que a pergunta seja clara e a resposta forneça uma explicação precisa e completa. \"\n",
    "        \"Use apenas um '\\\\n' para separar a pergunta e a resposta na sua resposta, e não inclua nenhum texto adicional. \"\n",
    "        \"A estrutura deve ser:\\n\"\n",
    "        \"Pergunta\\nResposta\"\n",
    "    )\n",
    "    \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        model=\"llama3-8b-8192\",\n",
    "    )\n",
    "\n",
    "    resposta_modelo = chat_completion.choices[0].message.content.strip()\n",
    "\n",
    "    return resposta_modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_perguntas_respostas_para_texto_longo(texto, limite_caracteres=10000):\n",
    "    perguntas_respostas = []\n",
    "    \n",
    "    partes_texto = dividir_texto(texto, limite_caracteres)\n",
    "    \n",
    "    for parte in partes_texto:\n",
    "        try:\n",
    "            resultado = gerar_pergunta_resposta(parte)\n",
    "            perguntas_respostas.append(resultado)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao gerar pergunta e resposta para uma parte do texto: {e}\")\n",
    "    \n",
    "    return perguntas_respostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_de_dados = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falta processar 113\n",
      "Falta processar 114\n",
      "Falta processar 115\n",
      "Falta processar 116\n",
      "Falta processar 117\n",
      "Falta processar 118\n",
      "Falta processar 119\n",
      "Falta processar 120\n",
      "Falta processar 121\n",
      "Falta processar 122\n",
      "Falta processar 123\n",
      "Falta processar 124\n",
      "Falta processar 125\n",
      "Falta processar 126\n",
      "Falta processar 127\n",
      "Falta processar 128\n",
      "Falta processar 129\n",
      "Falta processar 130\n",
      "Falta processar 131\n",
      "Falta processar 132\n",
      "Falta processar 133\n",
      "Falta processar 134\n",
      "Falta processar 135\n",
      "Falta processar 136\n",
      "Falta processar 137\n",
      "Falta processar 138\n",
      "Falta processar 139\n",
      "Falta processar 140\n",
      "Falta processar 141\n",
      "Falta processar 142\n",
      "Falta processar 143\n",
      "Falta processar 144\n",
      "Falta processar 145\n",
      "Falta processar 146\n",
      "Falta processar 147\n",
      "Falta processar 148\n",
      "Falta processar 149\n",
      "Falta processar 150\n",
      "Falta processar 151\n",
      "Falta processar 152\n",
      "Falta processar 153\n",
      "Falta processar 154\n",
      "Falta processar 155\n",
      "Falta processar 156\n",
      "Falta processar 157\n",
      "Falta processar 158\n",
      "Falta processar 159\n",
      "Falta processar 160\n",
      "Falta processar 161\n",
      "Falta processar 162\n",
      "Falta processar 163\n",
      "Falta processar 164\n",
      "Falta processar 165\n",
      "Falta processar 166\n",
      "Falta processar 167\n",
      "Falta processar 168\n",
      "Falta processar 169\n",
      "Falta processar 170\n",
      "Falta processar 171\n",
      "Falta processar 172\n",
      "Falta processar 173\n",
      "Falta processar 174\n",
      "Falta processar 175\n",
      "Falta processar 176\n",
      "Falta processar 177\n",
      "Falta processar 178\n",
      "Falta processar 179\n",
      "Falta processar 180\n",
      "Falta processar 181\n",
      "Falta processar 182\n",
      "Falta processar 183\n",
      "Falta processar 184\n",
      "Falta processar 185\n",
      "Falta processar 186\n",
      "Falta processar 187\n",
      "Falta processar 188\n",
      "Falta processar 189\n",
      "Falta processar 190\n",
      "Falta processar 191\n",
      "Falta processar 192\n",
      "Falta processar 193\n",
      "Falta processar 194\n",
      "Falta processar 195\n",
      "Falta processar 196\n",
      "Falta processar 197\n",
      "Falta processar 198\n",
      "Falta processar 199\n",
      "Falta processar 200\n",
      "Falta processar 201\n",
      "Falta processar 202\n",
      "Falta processar 203\n",
      "Falta processar 204\n",
      "Falta processar 205\n",
      "Falta processar 206\n",
      "Falta processar 207\n",
      "Falta processar 208\n",
      "Falta processar 376\n",
      "Falta processar 377\n",
      "Falta processar 378\n",
      "Falta processar 379\n",
      "Falta processar 380\n",
      "Falta processar 381\n",
      "Falta processar 382\n",
      "Falta processar 383\n",
      "Falta processar 384\n",
      "Falta processar 385\n",
      "Falta processar 386\n",
      "Falta processar 387\n",
      "Falta processar 388\n",
      "Falta processar 389\n",
      "Falta processar 390\n",
      "Falta processar 391\n",
      "Falta processar 392\n",
      "Falta processar 393\n",
      "Falta processar 394\n",
      "Falta processar 395\n",
      "Falta processar 396\n",
      "Falta processar 397\n",
      "Falta processar 398\n",
      "Falta processar 399\n",
      "Falta processar 400\n",
      "Falta processar 401\n",
      "Falta processar 402\n",
      "Falta processar 403\n",
      "Falta processar 404\n",
      "Falta processar 405\n",
      "Falta processar 406\n",
      "Falta processar 407\n",
      "Falta processar 408\n",
      "Falta processar 409\n",
      "Falta processar 410\n",
      "Falta processar 411\n",
      "Falta processar 412\n",
      "Falta processar 413\n",
      "Falta processar 414\n",
      "Falta processar 415\n",
      "Falta processar 416\n",
      "Falta processar 417\n",
      "Falta processar 418\n",
      "Falta processar 419\n",
      "Falta processar 420\n",
      "Falta processar 421\n",
      "Falta processar 422\n",
      "Falta processar 423\n",
      "Falta processar 424\n",
      "Falta processar 425\n",
      "Falta processar 426\n",
      "Falta processar 427\n",
      "Falta processar 428\n",
      "Falta processar 429\n",
      "Falta processar 430\n",
      "Falta processar 431\n",
      "Falta processar 432\n",
      "Falta processar 433\n",
      "Falta processar 434\n",
      "Falta processar 435\n",
      "Falta processar 436\n",
      "Falta processar 437\n",
      "Falta processar 438\n",
      "Falta processar 439\n",
      "Falta processar 440\n",
      "Falta processar 441\n",
      "Falta processar 442\n",
      "Falta processar 443\n",
      "Falta processar 444\n",
      "Falta processar 445\n",
      "Falta processar 446\n",
      "Falta processar 447\n",
      "Falta processar 448\n",
      "Falta processar 449\n",
      "Falta processar 450\n",
      "Falta processar 451\n",
      "Falta processar 452\n",
      "Falta processar 453\n",
      "Falta processar 454\n",
      "Falta processar 455\n",
      "Falta processar 456\n",
      "Falta processar 457\n",
      "Falta processar 458\n",
      "Falta processar 459\n",
      "Falta processar 460\n",
      "Falta processar 461\n",
      "Falta processar 462\n",
      "Falta processar 463\n",
      "Falta processar 464\n",
      "Falta processar 569\n",
      "Falta processar 570\n",
      "Falta processar 571\n",
      "Falta processar 572\n",
      "Falta processar 573\n",
      "Falta processar 574\n",
      "Falta processar 575\n",
      "Falta processar 576\n",
      "Falta processar 577\n",
      "Falta processar 578\n",
      "Falta processar 579\n",
      "Falta processar 580\n",
      "Falta processar 581\n",
      "Falta processar 582\n",
      "Falta processar 583\n",
      "Falta processar 584\n",
      "Falta processar 585\n",
      "Falta processar 586\n",
      "Falta processar 587\n",
      "Falta processar 588\n",
      "Falta processar 589\n",
      "Falta processar 590\n",
      "Falta processar 591\n",
      "Falta processar 592\n",
      "Falta processar 593\n",
      "Falta processar 594\n",
      "Falta processar 595\n",
      "Falta processar 596\n",
      "Falta processar 597\n",
      "Falta processar 598\n",
      "Falta processar 599\n",
      "Falta processar 600\n",
      "Falta processar 601\n",
      "Falta processar 602\n",
      "Falta processar 603\n",
      "Falta processar 604\n",
      "Falta processar 605\n",
      "Falta processar 606\n",
      "Falta processar 607\n",
      "Falta processar 608\n",
      "Falta processar 609\n",
      "Falta processar 610\n",
      "Falta processar 611\n",
      "Falta processar 612\n",
      "Falta processar 613\n",
      "Falta processar 614\n",
      "Falta processar 615\n",
      "Falta processar 616\n",
      "Falta processar 617\n",
      "Falta processar 618\n",
      "Falta processar 619\n",
      "Falta processar 620\n",
      "Falta processar 621\n",
      "Falta processar 622\n",
      "Falta processar 623\n",
      "Falta processar 624\n",
      "Falta processar 625\n",
      "Falta processar 626\n",
      "Falta processar 627\n",
      "Falta processar 628\n",
      "Falta processar 629\n",
      "Falta processar 630\n",
      "Falta processar 631\n",
      "Falta processar 632\n",
      "Falta processar 633\n",
      "Falta processar 634\n",
      "Falta processar 635\n",
      "Falta processar 636\n",
      "Falta processar 637\n",
      "Falta processar 638\n",
      "Falta processar 639\n",
      "Falta processar 787\n",
      "Falta processar 788\n",
      "Falta processar 789\n",
      "Falta processar 790\n",
      "Falta processar 791\n",
      "Falta processar 792\n",
      "Falta processar 793\n",
      "Falta processar 794\n",
      "Falta processar 795\n",
      "Falta processar 796\n",
      "Falta processar 797\n",
      "Falta processar 798\n",
      "Falta processar 799\n",
      "Falta processar 800\n",
      "Falta processar 801\n",
      "Falta processar 802\n",
      "Falta processar 803\n",
      "Falta processar 804\n",
      "Falta processar 805\n",
      "Falta processar 806\n",
      "Falta processar 807\n",
      "Falta processar 808\n",
      "Falta processar 809\n",
      "Falta processar 810\n",
      "Falta processar 811\n",
      "Falta processar 812\n",
      "Falta processar 813\n",
      "Falta processar 814\n",
      "Falta processar 815\n",
      "Falta processar 816\n",
      "Falta processar 817\n",
      "Falta processar 818\n",
      "Falta processar 819\n",
      "Falta processar 820\n",
      "Falta processar 821\n",
      "Falta processar 822\n",
      "Falta processar 823\n",
      "Falta processar 824\n",
      "Falta processar 825\n",
      "Falta processar 826\n",
      "Falta processar 827\n",
      "Falta processar 828\n",
      "Falta processar 829\n",
      "Falta processar 830\n",
      "Falta processar 831\n",
      "Falta processar 832\n",
      "Falta processar 833\n",
      "Falta processar 834\n",
      "Falta processar 835\n",
      "Falta processar 836\n",
      "Falta processar 837\n",
      "Falta processar 838\n",
      "Falta processar 839\n",
      "Falta processar 840\n",
      "Falta processar 841\n",
      "Falta processar 842\n",
      "Falta processar 843\n",
      "Falta processar 844\n",
      "Falta processar 845\n",
      "Falta processar 846\n",
      "Falta processar 847\n",
      "Falta processar 848\n",
      "Falta processar 849\n",
      "Falta processar 850\n",
      "Falta processar 851\n",
      "Falta processar 852\n",
      "Falta processar 853\n",
      "Falta processar 854\n",
      "Falta processar 855\n",
      "Falta processar 856\n",
      "Falta processar 857\n",
      "Falta processar 858\n",
      "Falta processar 859\n",
      "Falta processar 860\n",
      "Falta processar 861\n",
      "Falta processar 862\n",
      "Falta processar 863\n",
      "Falta processar 864\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for texto, num_instrucoes in zip(textos_legislacao, proporcao_perguntas):\n",
    "    for _ in range(num_instrucoes):\n",
    "        if len(texto) < 20000:\n",
    "            pergunta_resposta = gerar_pergunta_resposta(texto)\n",
    "            base_de_dados.append(pergunta_resposta)\n",
    "            sleep(20)\n",
    "        else:\n",
    "            print(f\"Falta processar {i}\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for texto, num_instrucoes in zip(textos_legislacao, proporcao_perguntas):\n",
    "    for _ in range(num_instrucoes):\n",
    "        if len(texto) >= 20000:\n",
    "            pergunta_resposta = gerar_perguntas_respostas_para_texto_longo(texto)\n",
    "            base_de_dados.append(pergunta_resposta)\n",
    "            sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(base_de_dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pergunta: Quais são as exigências para o credenciamento de instituições que oferecem cursos de educação a distância?\\n\\nResposta: A autorização, o reconhecimento de cursos e o credenciamento de instituições que oferecem cursos a distância devem observar o que estabelece este Decreto e a legislação específica. O credenciamento é limitado a cinco anos e pode ser renovado após avaliação. A avaliação seguirá procedimentos, critérios e indicadores de qualidade definidos em ato próprio expedido pelo Ministro de Estado da Educação e do Desporto.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_de_dados[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isString(item):\n",
    "    if isinstance(item, str): return [item]\n",
    "    else: return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_perguntas_respostas(item):\n",
    "    perguntas_respostas = []\n",
    "    \n",
    "    matches = re.findall(r'Pergunta:\\s*(.*?)\\n\\nResposta:\\s*(.*)', item, re.DOTALL)\n",
    "    \n",
    "    if not matches:\n",
    "        parts = item.split('\\n\\n')\n",
    "        if len(parts) >= 2:\n",
    "            pergunta = parts[0].strip()\n",
    "            resposta = parts[1].strip()\n",
    "            perguntas_respostas.append({\n",
    "                'prompt': pergunta,\n",
    "                'completion': resposta\n",
    "            })\n",
    "    else:\n",
    "        for pergunta, resposta in matches:\n",
    "            pergunta = pergunta.strip()\n",
    "            resposta = resposta.strip()\n",
    "            perguntas_respostas.append({\n",
    "                'prompt': pergunta,\n",
    "                'completion': resposta\n",
    "            })\n",
    "    \n",
    "    return perguntas_respostas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for item in base_de_dados:\n",
    "    if isinstance(item, str):\n",
    "        resultado = separar_perguntas_respostas(item)\n",
    "        dataset.extend(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('perguntas_respostas.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['text', 'completion']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for entry in dataset:\n",
    "        json_entry = json.dumps(entry, ensure_ascii=False)\n",
    "        csvfile.write(f\"{json_entry}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
